{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 class=\"text-center\">Introduction to Machine Learning: Titanic learning from the disaster</h1>\n",
    "<h2 class=\"text-center\">February, 2022</h2>\n",
    "\n",
    "\n",
    "The purpose of this tutorial is to to predict who will survive and who will die on the Titanic using passengers data (age, ticket price, class, etc). The data are coming from a [Kaggle datascience competition](https://www.kaggle.com/c/titanic). You will use Pandas to load and pre-process the data and Sklearn for the classification part. \n",
    "\n",
    "\n",
    "![](img/dicap_titanic.png)\n",
    "\n",
    "- In Section I, exploration data analysis, visualization and basic prediction based on gender\n",
    "- In Section II, data pre-processing: scalling, missing values and categorical data encoding\n",
    "- In Section III, a first pipeline using Logistic Regression \n",
    "- In Section IV, a second pipeline using RandomForest\n",
    "- üìú The last section (V) is the evaluation. We will ask you to improve and explore other pipelines (XGBoost, Ensemble Learning,...). You would have 2 weeks to do so and share with us the code + 1 page explication on your method (more details in the Section).\n",
    "\n",
    "The code must be completed after each ‚ùì **Question** ‚ùì. A blank cell with \"HERE\" appears as a comment in the code. The parameters that do not change the course of the story are accompanied \"EDIT ME!\" as a comment: you can change them at the time or at the end of the section to see the changes involved.\n",
    "\n",
    "You can also find some üî¥ HINTS üî¥ with associated links to documentation and usefull functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "import numpy as np # library for numerical analysis\n",
    "import pandas as pd # library for data manipulation: data frame\n",
    "import matplotlib.pyplot as plt # library for plotting\n",
    "import seaborn as sns # advanced library for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section I\n",
    "\n",
    "Load the train CSV file using pandas and display the 5 first rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"input/train.csv\") \n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got a column `Survived` that corresponds to the label we will try to predict.  \n",
    "The `NaN` means that the value is missing. It is something we would need to investigate and correct. \n",
    "\n",
    "#### ‚ùì **Question** ‚ùì Now do the same with test data.\n",
    "üî¥ HINTS üî¥  \n",
    "`input/test.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no `Survived` column in the test set, of course !\n",
    "\n",
    "### Exploration Data Analysis (EDA)\n",
    "\n",
    "First we will explore the data and do some plotting to know better what we have at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We have 891 training examples (passengers), that is quite limited but still OK to do Machine Learning.\n",
    "\n",
    "* It seems that some values are missing (`NaN`). We would need to how many values are missing for each feature.\n",
    "\n",
    "* Some features are categorical (e.g. `Sex`, `Pclass`, `Embarked`), some other numerical (`Age`, `Fare`, `SibSp`, `Parch`) and finally some alphanumeric (`Ticket`, `Cabin`). We would need to transform the categorical data so they can be processed by a classifier (only numerical data).\n",
    "\n",
    "### Missing values\n",
    "üî¥ HINTS üî¥  \n",
    "We will use [`pd.isnull`](https://pandas.pydata.org/docs/reference/api/pandas.isnull.html) function to detect and count missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.isnull(train).sum()/len(train)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Cabin` features is missing for 77.1% of the passengers, so we would probably drop it as too many values are missing. \n",
    "\n",
    "`Age` is probably an important feature and missing for ~20% of the passengers. We will try to fill the gaps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Intuitions on the data\n",
    "* Based on the movie and on the custom \"women and children first\", women and kids are probably more likely to survive.\n",
    "* People in first class are more likely to survive as their cabin is closer to the deck (top of the boat). \n",
    "* People traveling alone are more likely to survive as they did not have to wait for relatives that may be slower. \n",
    "\n",
    "Let do some plotting to check our intuitions.\n",
    "\n",
    "#### Male/Female\n",
    "üî¥ HINTS üî¥\n",
    "- With Pandas to select a column you can simply use: `train[\"Sex\"]`\n",
    "- [`df.value_counts(normalize = True)`](https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html) counts unique values and return a normalized count\n",
    "- [`df.plot(kind='bar')`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html) will plot an histogram of the values\n",
    "\n",
    "Draw a first bar plot of sex survival by sex and compute mean percentage of male and woman who survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Sex\"].value_counts(normalize = False).plot(kind='bar', ylabel='Number of passengers')\n",
    "print(\"Percentage of male: {0:.2f}%\".format(train[\"Sex\"].value_counts(normalize = True)[0]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot survival rate for womens\n",
    "Here we will use [Matplotlib](https://matplotlib.org/) library directly and not trough Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = train[\"Survived\"][train[\"Sex\"] == 'female'].value_counts(normalize = False)\n",
    "_ = plt.bar(x=count.index, height=count)\n",
    "_ = plt.ylabel('Number of passengers')\n",
    "_ = plt.xticks(ticks=[0,1], labels=['Dead', 'Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ùì **Question** ‚ùì Do the same with `male`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ùì **Question** ‚ùì Print the proportions in percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if we predict that all males will die and all female will survive we would reach an accuracy of: $0.6476\\times(1-0.1889) + (1-0.6476)*0.7420)$ = 78.7%. \n",
    "\n",
    "Not bad ! Will be hard to beat !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passenger class feature: `Pclass`\n",
    "We will do the same analysis with passenger this time using an advanced library for plotting: [Seaborn](https://seaborn.pydata.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Pclass\", y=\"Survived\", data=train)\n",
    "\n",
    "print(\"Percentage of Pclass = 1 who survived: {0:.2f}%\".format(train[\"Survived\"][train[\"Pclass\"] == 1].value_counts(normalize = True)[1]*100))\n",
    "\n",
    "print(\"Percentage of Pclass = 2 who survived: {0:.2f}%\".format(train[\"Survived\"][train[\"Pclass\"] == 2].value_counts(normalize = True)[1]*100))\n",
    "\n",
    "print(\"Percentage of Pclass = 3 who survived: {0:.2f}%\".format(train[\"Survived\"][train[\"Pclass\"] == 3].value_counts(normalize = True)[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This could be intersected with the `Sex` feature to improve our first naive classifier.\n",
    "\n",
    "\n",
    "üî¥ HINTS üî¥  \n",
    "It uses the [`groupby`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html?highlight=groupby#pandas.DataFrame.groupby) function from Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby(['Pclass','Sex'])['Survived'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "96.8% of women from first class have survived and only 13.5% of men from thrid class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ùì **Question** ‚ùì Create other `grouby` like that to see if we can do bettter ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Section 2: missing values and data pre-processing\n",
    "In the`Cabin` feature many values are missing.It is very unlikely that `Ticket` number contains any useful information.\n",
    "\n",
    "#### ‚ùì **Question** ‚ùì Drop the `Cabin` and Ticket number feature.\n",
    "\n",
    "üî¥ HINTS üî¥   \n",
    "Use the function [`df.drop('col_name', axis='columns')`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html?highlight=drop#pandas.DataFrame.drop) to drop a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode non-numerical labels\n",
    "In the `Name` feature each passenger has a title that we will use to infer age when it is missing. For instance usually *Miss* and *Master* refer to people of younger age than *Mrs.* or *Mr.*\n",
    "\n",
    "We will encode the non-numerical labels to a numerical value: *Master* $\\rightarrow$ 0, *Miss* $\\rightarrow$ 1, ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Name.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî¥ HINTS üî¥   \n",
    "We want the letters after the first *space* and end it after the `.`  \n",
    "We will use **regular expression (regex)** on string with the [`extract`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.extract.html?highlight=extract#pandas.Series.str.extract) function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put train and test in a list to do it on both\n",
    "combine = [train, test]\n",
    "\n",
    "# For train and test do:\n",
    "for dataset in combine:\n",
    "    str_names = dataset.Name.str # Get name column and convert it ot string\n",
    "    \n",
    "    # Perform reg-ex on it: extract letters after the first space and stop after the .\n",
    "    # expand = Flase returns a Serie and not a DataFrame\n",
    "    \n",
    "    titles = str_names.extract(' ([A-Za-z]+)\\.', expand=False) \n",
    "    # Put that in a new column\n",
    "    dataset['Title'] = titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ùì **Question** ‚ùì  \n",
    "Use the [`pd.crosstab(index, column)`](https://pandas.pydata.org/docs/reference/api/pandas.crosstab.html?highlight=cross%20tab#pandas.crosstab) function to create a cross tabulation between `Title` and `Sex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace various titles with more common names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Capt', 'Col',\n",
    "    'Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    \n",
    "    dataset['Title'] = dataset['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ùì **Question** ‚ùì  \n",
    "Use the [preprocessing.LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) function from Sklearn to encode the title to a numerical value.\n",
    "\n",
    "üî¥ HINTS üî¥   \n",
    "You can use `train[\"Title\"].values` to extract the Title list in the form of an array (no more a Pandas structure).  \n",
    "\n",
    "You need to define first an encoder: `le = preprocessing.LabelEncoder()`, then `fit` it to some values and finally `transform` the title and replace the values in the [`Title`] column (or create a new column and drop `Title` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ùì **Question** ‚ùì  \n",
    "Use again `value_counts` to count the occurence of each title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Filling Age missing values\n",
    "\n",
    "First we need to discretize the ages. It does not matter if a passenger is 31 or 32, what matter is that the passenger is young.  \n",
    "\n",
    "We have defined a first dicretization: `[0, 5, 12, 18, 24, 35, 60, 100]` and you can modify it later.\n",
    "\n",
    "üî¥ HINTS üî¥   \n",
    "\n",
    "- `df[\"Column\"].fillna(value)` replace all the `NaN` values in `Column` by `value`.\n",
    "- [`pd.cut`](https://pandas.pydata.org/docs/reference/api/pandas.cut.html?highlight=cut#pandas.cut) can be used to cut our continus Age data into segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Age\"] = train[\"Age\"].fillna(-0.5) \n",
    "test[\"Age\"] = test[\"Age\"].fillna(-0.5)\n",
    "\n",
    "# The bins for the age group and corresponding labels\n",
    "bins = [-1, 0, 5, 12, 18, 24, 35, 60, np.inf] # EDIT ME\n",
    "labels = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n",
    "\n",
    "# \n",
    "train['AgeGroup'] = pd.cut(train[\"Age\"], bins, labels = labels)\n",
    "test['AgeGroup'] = pd.cut(test[\"Age\"], bins, labels = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ùì **Question** ‚ùì  \n",
    "Use Seaborn to draw a bar plot of AgeGroup vs Survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use this Age Group to intersect it with the Title use the most frequent age group for each title."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill missing age values using a correspondance between Title and mode of each AgeGroup.\n",
    "\n",
    "1. Find the [mode](https://en.wikipedia.org/wiki/Mode_(statistics)) for each AgeGroup.\n",
    "2. Make a correspondance between AgeGroup and Title\n",
    "3. Fill the msising values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_age = train[train[\"Title\"] == 0][\"AgeGroup\"].mode() #Baby\n",
    "miss_age = train[train[\"Title\"] == 1][\"AgeGroup\"].mode() #Student\n",
    "mr_age = train[train[\"Title\"] == 2][\"AgeGroup\"].mode() #Young Adult\n",
    "mrs_age = train[train[\"Title\"] == 3][\"AgeGroup\"].mode() #Adult\n",
    "rare_age = train[train[\"Title\"] == 4][\"AgeGroup\"].mode() #Adult\n",
    "royal_age = train[train[\"Title\"] == 5][\"AgeGroup\"].mode() #Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_title_mapping = {0: \"Baby\", 1: \"Student\", 2: \"Young Adult\", 3: \"Adult\", 4: \"Adult\", 5: \"Adult\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For train\n",
    "for x in range(len(train[\"AgeGroup\"])):\n",
    "    if train[\"AgeGroup\"][x] == \"Unknown\":\n",
    "        train[\"AgeGroup\"][x] = age_title_mapping[train[\"Title\"][x]]\n",
    "\n",
    "# For  test\n",
    "for x in range(len(test[\"AgeGroup\"])):\n",
    "    if test[\"AgeGroup\"][x] == \"Unknown\":\n",
    "        test[\"AgeGroup\"][x] = age_title_mapping[test[\"Title\"][x]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embarked Feature: fill missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ùì **Question** ‚ùì  \n",
    "How many people have embarked from Southampton (S), Cherbourg (C) and Queenstown (Q) ?\n",
    "\n",
    "üî¥ HINTS üî¥  \n",
    "`value_counts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear that the majority of people embarked in Southampton (S). We will fill in the missing values with S."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ùì **Question** ‚ùì  \n",
    "Replacing the missing values in the Embarked feature with S\n",
    "\n",
    "üî¥ HINTS üî¥   \n",
    "`fillna`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encoding\n",
    "We could encode with S: 0, C: 1 and Q: 2 but it would mean that S is closer to C than Q which may not be true in practice. So instead we will create 3 collumns that encode for S, C and Q."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ‚ùì **Question** ‚ùì  \n",
    "Create 3 collumns that encode for S, C and Q.\n",
    "\n",
    "üî¥ HINTS üî¥   \n",
    "[`pd.get_dummies`](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ùì **Question** ‚ùì Drop name feature\n",
    "üî¥ HINTS üî¥   \n",
    "`df.drop(['Column_name'], axis='column')` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ùì **Question** ‚ùì Encode sex feature\n",
    "üî¥ HINTS üî¥   \n",
    "`le = preprocessing.LabelEncoder()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ùì **Question** ‚ùì Drop fare values as it is redundant with class information\n",
    "üî¥ HINTS üî¥   \n",
    "`df.drop(['Column_name'], axis='column')` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ùì **Question** ‚ùì Encode age groupe and drop age column\n",
    "üî¥ HINTS üî¥   \n",
    "- `le = preprocessing.LabelEncoder()` \n",
    "- `df.drop(['Column_name'], axis='column')` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Section III: Classification using [Logisitic Regresssion](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression#sklearn.linear_model.LogisticRegression)\n",
    "\n",
    "### [Train/validation split](https://scikit-learn.org/stable/modules/cross_validation.html) \n",
    "We will divide the training data in two sets:\n",
    "- The train set to train the model on\n",
    "- The validation set to estimate performance and track it\n",
    "\n",
    "‚ö†Ô∏è The validation set is different from the test set defined above. This validaton set is used to have an estimation of the classification performance while the test set is used in the competition (we don't have the corresponding labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get labels\n",
    "targets = train[\"Survived\"] \n",
    "predictors = train.drop(['Survived', 'PassengerId'], axis=1) # PassengerId is only useful to take part to Kaggle competition\n",
    "X_test = test.drop(['PassengerId'], axis=1)\n",
    "\n",
    "# Use 20% of data as validation\n",
    "x_train, x_val, y_train, y_val = train_test_split(predictors, targets, test_size = 0.20, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "Here we will use [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html) from Sklearn. It allows to chain pre-processing operators (here standard deviation normalization) with classifier in a pipeline. \n",
    "You have to: \n",
    "1. Instanciate a classifier and set the hyper-parameters (here they are left to default)\n",
    "2. Put pre-processing and classifier in a Pipeline\n",
    "6. Train the pipeline. In scikit-learn, all classifier have `.fit(X_train, y_train)` method to train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "clf = LogisticRegression()  # EDIT ME\n",
    "\n",
    "model = make_pipeline(StandardScaler(), clf)\n",
    "\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate performance\n",
    "After training the model, you can call `clf.predict(X)` to compute a prediction.  \n",
    "With the validation set we will have an estimation of the performance of the model. Estimating the performance on the same set that has been used for training would be overfiting. It is the same when you take an exam: questions are from the same set that you had during lectures but not exactlly the same otherwise to avoid by heart.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "acc_logreg = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(\"Accuracy on the validation set: {0:.2f}%\".format(acc_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Less than the guess on gender !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with anoter train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 20% of data as validation\n",
    "x_train, x_val, y_train, y_val = train_test_split(predictors, targets, test_size = 0.20, random_state = 55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(StandardScaler(), clf)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "acc_logreg = model.score(x_val, y_val) * 100\n",
    "print(\"Accuracy on the validation set: {0:.2f}%\".format(acc_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's 1% better !! Depending on the train/split we can have large difference in the estimation of the accuracy (here about 3%). One should be able to measure and take into account the variance of this estimation.\n",
    "\n",
    "[**Cross-validation**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) was designed for the estimation of accuracy variance ! The training data are divided into **K** folds, **K-1** folds are used to train model and 1 fold to estimate performance. Then the folds used to train and test the model are rotated so we obtain **K** estimation of the performance with **K** distinct training sets.\n",
    "\n",
    "![](img/grid_search_cross_validation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ùì **Question** ‚ùì Use [`cross_val_score`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) to perform 5-folds cross validation for the accuracy estimation. \n",
    "üî¥ HINTS üî¥   \n",
    "- `n_jobs = -1` option allows to run the training for each fold in parallel.\n",
    "- Another scoring method can be provided to the `scoring` argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean accuracy on the 5-folds cross-validation : {0:.2f}%\".format(scores.mean()))\n",
    "print(\"Standard deviation of the accuracy on the 5-folds cross-validation : {0:.2f}%\".format(scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take part to the Kaggle competition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this `submission.csv` file to try to participate to the Kaggle competition ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance with Logistic Regression\n",
    "Logistic Regression is a linear regression associated with a non-linearity: sigmoid function (more details in the slides of the lecture).\n",
    "\n",
    "You can access the weights of the linear regression to estimate feature importance. It would provide some interpretability to the model.  \n",
    "\n",
    "\n",
    "‚ö†Ô∏è This feature importance is associated with the model, it is not something that should be extrapolated further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model[1].coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[1].coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = pd.DataFrame(\n",
    "   model[1].coef_.T,\n",
    "   columns=['Coefficients'], index=x_train.columns\n",
    ")\n",
    "\n",
    "coefs.plot(kind='barh', figsize=(9, 7))\n",
    "plt.title('Logistic Regression model')\n",
    "plt.axvline(x=0, color='.5')\n",
    "plt.subplots_adjust(left=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section IV: Classification using RandomForest\n",
    "\n",
    "![](https://i.imgur.com/AC9Bq63.png)\n",
    "\n",
    "#### ‚ùì **Question** ‚ùì Do the same but this time with a Random Forest classifier and using only 4 features: **\"Pclass\"**, **\"Sex\"**, **\"SibSp\"**, and **\"Parch\"**. \n",
    "üî¥ HINTS üî¥   \n",
    "- `from sklearn.ensemble import RandomForestClassifier`\n",
    "- `rf = RandomForestClassifier(n_estimators=20, max_depth=2, max_features=2, random_state=1)` \n",
    "\n",
    "\n",
    "With random forest you can also plot feature importance: https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "# HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section V: harder, bettter, faster, stronger\n",
    "\n",
    "### üìú Evaluation\n",
    "\n",
    "You will be evaluated on two aspects: \n",
    "1. On the testing score: do your best and try to avoid overfitting !\n",
    "2. A small report (1 page max) explaining your method and the choices you made: try to justify here the choice you made and why it improved the performance.\n",
    "\n",
    "We expect your code (a standalone Python script or notebook) and the 1 page report in a *.zip* file by email to <ludovic.darmet@isae-supaero.fr> before the 15th of February. \n",
    "\n",
    "#### ‚ùì **Question** ‚ùì Try to do better !!\n",
    "üî¥ HINTS üî¥\n",
    "* Have a [cross-validation procedure](https://scikit-learn.org/stable/modules/cross_validation.html) for better performance estimation\n",
    "* Use more features and [select them](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html#sklearn.feature_selection.SequentialFeatureSelector)\n",
    "* Optimized hyper-parameters (using [`GridSearch`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV);\n",
    "* More advanced classification algorithms such as [`Gradient Boosting classifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
