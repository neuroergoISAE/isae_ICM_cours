{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce875acd",
   "metadata": {},
   "source": [
    "<h1 class=\"text-center\">BCI - Introduction to EEG classification for a MI BCI</h1>\n",
    "<h2 class=\"text-center\">February, 2022</h2>\n",
    "\n",
    "<br>\n",
    "\n",
    "The purpose of this tutorial is to implement a Motor Imagery BCI, using a public dataset (Cho, H., Ahn, M., Ahn, S., Kwon, M. and Jun, S.C., 2017. EEG datasets for motor imagery brain computer interface. GigaScience.). You will use MNE to load and pre-process the data and Sklearn+MNE for the classification part. \n",
    "</b></div>\n",
    "\n",
    "- In Section I, exploration data analysis and epoching using MNE\n",
    "- In Section II, a first classifier is trained based on Common Spatial Patterns and Linear Discriminant Analysis.\n",
    "- In Section III, some possible improvements of this baseline pipeline\n",
    "- MOABB toolbox is used in Section IV to implement more elaborated pipeline\n",
    "- The last section (V) is an opportunity to improve and explore other pipelines from what you learnt today.\n",
    "\n",
    "The code must be completed after each ‚ùì **Question** ‚ùì A blank cell with \"HERE\" appears as a comment in the code. The parameters that do not change the course of the story are accompanied \"EDIT ME!\" as a comment: you can change them at the time or at the end of the section to see the changes involved.\n",
    "\n",
    "You can also find some üî¥ HINTS üî¥ with associated links to documentation and usefull functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21742d68",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    " Then we define a hack that will hide the very verbose output of some functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c104a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c604ed",
   "metadata": {},
   "source": [
    "# I - Motor Imagery Dataset: \n",
    "\n",
    "**Subjects were asked to imagine the hand movement (left vs right) depending on the instruction given.** \n",
    "\n",
    "Five or six runs were performed during the MI experiment. After each run, we calculated the classification accuracy over one run and gave the subject feedback to increase motivation. Between each run, a maximum 4-minute break was given depending on the subject‚Äôs demands. (cf [MOABB dataset](http://moabb.neurotechx.com/docs/generated/moabb.datasets.Cho2017.html) or\n",
    "[gigadb datasets](http://gigadb.org/dataset/100295))\n",
    "\n",
    "\n",
    "EEG data were collected using 64 Ag/AgCl active electrodes. A 64-channel montage based on the international 10-20 system was used to record the EEG signals with 512 Hz sampling rates. The EEG device used in this experiment was the Biosemi ActiveTwo system. The BCI2000 system 3.0.2 was used to collect EEG data and present instructions (left hand or right hand MI). \n",
    "\n",
    "### We load the dataset, and plot the sensor locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f92cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from moabb.datasets import Cho2017\n",
    "\n",
    "# define and load the dataset\n",
    "ds = Cho2017()\n",
    "raws = ds.get_data(subjects=[1,2])\n",
    "raw = raws[1]['session_0']['run_0']\n",
    "\n",
    "# show infos\n",
    "print(raw.info)\n",
    "\n",
    "# display the montage (sensors on the scalp)\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "raw.plot_sensors(ch_type='eeg',show_names=True, kind='3d')\n",
    "#plt.show()\n",
    "raw.plot_sensors(ch_type='eeg',show_names=True)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61daeba5",
   "metadata": {},
   "source": [
    "### Here we plot the EEG data, that is:\n",
    "$$ \\mathbb{S} = \\begin{pmatrix} s_{11} & s_{12} & \\ldots & s_{1T}\\\\\n",
    "                        s_{21} & s_{22} & \\ldots & s_{2T}\\\\\n",
    "                        \\cdots & & & \\cdots\\\\\n",
    "                        s_{C1} & s_{C2} & \\ldots & s_{CT} \\end{pmatrix} $$\n",
    "with $T$ the number of time points in the considered interval $[t_{min},t_{max}]$, $C$ the number of channels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f0927a-8199-4d84-a177-ea5146fbdf25",
   "metadata": {},
   "source": [
    "### ‚ùì **Question** ‚ùì Explore the signal and change the filtering options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c4bbb5-d7b0-4acd-a473-ab3e0773ac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 150\n",
    "scal = dict(eeg=1e-3)                      # EDIT ME!\n",
    "raw.plot(n_channels=64, scalings=scal,\n",
    "         start=15, duration=2,             # EDIT ME!\n",
    "         lowpass=200, highpass=5,          # EDIT ME!\n",
    "         show_scrollbars=False, show_scalebars=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c46855",
   "metadata": {},
   "source": [
    "### Let's show some of the studied events\n",
    "#### ‚ùì **Question** ‚ùì Explore the signal and change the filtering options\n",
    "\n",
    "üî¥ HINTS üî¥  \n",
    "Along the EEG data, they are some **Markers** that are triggers that corresponds to events. The **markers** are syncronized with EEG so it is possible to superimpose it.\n",
    "\n",
    "We will use MNE function [`find_events`](https://mne.tools/stable/generated/mne.find_events.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f637fd-9dea-43df-8792-a03988f4d27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne import find_events\n",
    "\n",
    "# Get the event (left / right hand) by looking at the \"stim\" channel.\n",
    "events = find_events(raw, shortest_event=0, verbose=True)\n",
    "\n",
    "# Display tge EEG signals with the events \n",
    "scal = dict(eeg=5e-3)     # EDIT ME!\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "raw.plot(events=events, event_color='red', event_id=ds.event_id,\n",
    "         scalings=scal, clipping=None, show_scrollbars=False, show_scalebars=False, \n",
    "         start=680,       # EDIT ME!\n",
    "         duration=40,     # EDIT ME!\n",
    "         n_channels=64)   # EDIT ME!\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b244b8a9-9d7b-4bc1-831c-6a6196f9e95f",
   "metadata": {},
   "source": [
    "### Power Spectral Density (PSD)\n",
    "\n",
    "We will perform the Fast Fourier Transform of the signal to study it in the frequency domain.\n",
    "\n",
    "#### ‚ùì **Question** ‚ùì Try some other filtering and cropping of the data to see how it impact the PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05abf7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_left = raw.copy()\n",
    "\n",
    "# crop data between tmin and tmax\n",
    "tmin,tmax=0,600                                                          # EDIT ME!\n",
    "raw_left.crop(tmin,tmax)                                                     \n",
    "\n",
    "# filter data\n",
    "raw_left.filter(7., 30., fir_design='firwin', skip_by_annotation='edge') # EDIT ME!\n",
    "\n",
    "# power spectral density\n",
    "raw_left.plot_psd()\n",
    "#plt.show()\n",
    "\n",
    "# topomap with power spectral densities\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "raw_left.plot_psd_topo()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b760a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Let's epoch the data:\n",
    "\n",
    "The **markers** will now be used to slice data accordingly and select **epochs** of interest.\n",
    "\n",
    "\n",
    "Each epoch $\\mathbb{S}_i$, with $i \\in \\{1, \\ldots, n\\}$, corresponds to a time window located at a given **event**.\n",
    "An epoch will produce a sample to be classified, *i.e.* a row of the matrix\n",
    "$$ \\mathbb{X} = \\begin{pmatrix}\n",
    "f_1(\\mathbb{S}_1) & f_2(\\mathbb{S}_1) & \\ldots & f_d(\\mathbb{S}_1)\\\\\n",
    "f_1(\\mathbb{S}_2) & f_2(\\mathbb{S}_2) & \\ldots & f_d(\\mathbb{S}_2)\\\\\n",
    "\\cdots & & & \\cdots\\\\\n",
    "f_1(\\mathbb{S}_n) & f_2(\\mathbb{S}_n) & \\ldots & f_d(\\mathbb{S}_n)\\\\\n",
    "\\end{pmatrix}.$$\n",
    "\n",
    "\n",
    "üî¥ HINTS üî¥  \n",
    "- [`Epochs`](https://mne.tools/stable/auto_tutorials/epochs/10_epochs_overview.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11beb05f-df7e-48f1-a1d2-11239bf58a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne import Epochs, find_events, pick_types\n",
    "\n",
    "def load_epoch(raws, subject_nb, event_id, fmin = 7., fmax = 35.):\n",
    "    \"\"\"Function to load epoched data for a specified subject\"\"\"\n",
    "    \n",
    "    raw = raws[subject_nb]['session_0']['run_0']\n",
    "\n",
    "    # Apply band-pass filter\n",
    "    raw.filter(fmin, fmax, fir_design='firwin', skip_by_annotation='edge')\n",
    "\n",
    "    # Get the event (left / right hand) by looking at the \"stim\" channel.\n",
    "    events = find_events(raw, shortest_event=0, verbose=True)\n",
    "\n",
    "    picks = pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "                       exclude='bads')\n",
    "    tmin, tmax = -1., 4.\n",
    "    # Read epochs (train will be done only between 1 and 2s)\n",
    "    # Testing will be done with a running classifier\n",
    "    epochs = Epochs(raw, events, event_id, tmin, tmax, proj=True, picks=picks,\n",
    "                    baseline=None, preload=True)\n",
    "    labels = epochs.events[:, -1] - 1\n",
    "    return epochs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db53b39e-894b-4121-9cba-ab1daadb8d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Cho2017()\n",
    "event_id = ds.event_id\n",
    "raws = ds.get_data(subjects=[1,2])\n",
    "\n",
    "epochs, labels = load_epoch(raws, 1, event_id)\n",
    "epoch_train = epochs.copy().crop(tmin=1., tmax=2.)\n",
    "epochs_data_train = epoch_train.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f965d98c-feb2-4cb4-aa44-d0ee3361375d",
   "metadata": {},
   "source": [
    "### Some plotting for the data epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31abbf9e-71b9-4d4c-8c89-9ee28354901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show epochs\n",
    "plt.rcParams['figure.figsize'] = [15, 5]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "max_sample = 4\n",
    "max_channel= 8\n",
    "first_epoch = 98\n",
    "for s in range(max_sample):\n",
    "    for c in range(max_channel):\n",
    "        index = s*max_channel + c + 1\n",
    "        plt.subplot(max_sample, max_channel, index)\n",
    "        plt.axis('off')\n",
    "        plt.plot(epoch_train.get_data()[s+first_epoch,c,:])\n",
    "        title = f'E{s+first_epoch+1} C{c+1} L={labels[s+first_epoch]}'\n",
    "        plt.title(title, fontsize=7)\n",
    "plt.suptitle('EEG Dataset (E=epoch, C=channel, L=label)');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd701a24",
   "metadata": {},
   "source": [
    "# II - A first classification pipeline: CSP + LDA\n",
    "#### ‚ùì **Question** ‚ùì Assemble a first classification pipeline with:\n",
    "\n",
    "1. Common Spatial Filter (feature extractor) \n",
    "2. Linear Discriminant Analysis as classifier\n",
    "\n",
    "$$ \\mbox{EEG data} \\rightarrow CSP \\rightarrow LDA \\rightarrow \\mbox{prediction}$$ \n",
    "\n",
    "üî¥ HINTS üî¥\n",
    "1. [CSP](https://mne.tools/0.23/generated/mne.decoding.CSP.html): `csp = CSP(n_components=4, reg=None, log=True, norm_trace=False)`\n",
    "2. [LinearDiscriminantAnalysis](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html)\n",
    "3. [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) $\\rightarrow$ reminder about how to use Pipeline in the Titanic BE in Section III."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db72368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mne.decoding import CSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd948d8c-be1f-4144-bc83-ddc02abbb3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble CSP feature extractor\n",
    "# HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dd9785-1b67-4161-b2c0-9136aeefeeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble a classifier: LinearDiscriminantAnalysis\n",
    "# HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2a336c-7be7-4bd1-93ae-33cc466e88a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn Pipeline\n",
    "# HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e837a8b",
   "metadata": {},
   "source": [
    "#### ‚ùì **Question** ‚ùì: use the sklearn functions [ShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit) and [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) to evaluate this classifier.\n",
    "\n",
    "üî¥ HINTS üî¥  \n",
    "- `ShuffleSplit` is used to create multiple train/test split in the data. \n",
    "- `cross_val_score` accept an outside splitter for cross validation (such as`ShuffleSplit`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365cc923-29c2-49eb-837c-c4aef0f018c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "epochs_data = epochs.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18424cd8-06ef-434e-b3bf-eaf91037a00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define shuffle split strategy\n",
    "# HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e852030-45a3-4b6a-987b-a4d9162998d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the resulting classifier using cross-validation\n",
    "# HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07944a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the results\n",
    "class_balance = np.mean(labels == labels[0])\n",
    "class_balance = max(class_balance, 1. - class_balance)\n",
    "print(\"\\n\\nClassification accuracy: %f / Chance level: %f \\n\\n\" % (np.mean(scores),\n",
    "                                                          class_balance))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8f6b6d",
   "metadata": {},
   "source": [
    "### We display now the CSP patterns\n",
    "This corresponds to the weigths of the filters applied on each electrode. We have learned 4 filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7de634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot CSP patterns estimated on full data for visualization\n",
    "with HiddenPrints():\n",
    "    csp.fit_transform(epochs_data, labels)\n",
    "    \n",
    "print(csp.get_params())\n",
    "\n",
    "#plt.rcParams['axes.grid'] = False\n",
    "#csp.plot_filters(epochs.info, ch_type='eeg', units='Filters (AU)', size=1.5)\n",
    "#plt.show()\n",
    "\n",
    "plt.rcParams['axes.grid'] = False\n",
    "csp.plot_patterns(epochs.info, ch_type='eeg', units='Patterns (AU)', size=1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073b8b78",
   "metadata": {},
   "source": [
    "### Test the classifier on a sliding window\n",
    "\n",
    "Here, we would wike to evaluate the predictive power of our pipeline using epochs of different length. It should help us to determine what is the minimal length to consider to have a reliable classfication.\n",
    "\n",
    "#### ‚ùì **Question** ‚ùì:\n",
    "- First, compute cv_split using the its *split* attribute of the [ShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit) cross-validation ```cv```.\n",
    "- Then, in the loop on the couples (Training set,Validation set) of cv_split: \n",
    "    - compute X_train using the method *fit_transform* of the [Common Spatial Pattern](https://mne.tools/0.23/generated/mne.decoding.CSP.html) ```csp``` defined earlier, on the the epochs of the training set ```epochs_data_train[train_idx]``` and the labels ```y_train```.\n",
    "    - train the [LinearDiscriminantAnalysis](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html) classifier ```lda``` defined earlier using its method *fit* on the features ```X_train``` and the labels ```y_train```.\n",
    "    - then, in the loop on the sliding windows, compute X_test using the method *transform* of the [Common Spatial Pattern](https://mne.tools/0.23/generated/mne.decoding.CSP.html) ```csp``` just trained, on the epochs of the testing set ```epochs_data[test_idx][:, :, n:(n + w_length)]```.\n",
    "    \n",
    "üî¥ HINTS üî¥\n",
    "- `csp.fit_transform` and `csp.transform`\n",
    "- `lda.fit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb2107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfreq = raw.info['sfreq']\n",
    "print(f'Sampling frequency: {sfreq}')\n",
    "\n",
    "# window length = number of samples during 0.5secs\n",
    "w_length = int(sfreq * 0.5)   # running classifier: window length \n",
    "# window step size = number of samples during 0.1secs\n",
    "w_step = int(sfreq * 0.1)  # running classifier:\n",
    "# different starting indices considering a w_length-length window and a w_step-length step\n",
    "w_start = np.arange(0, epochs_data.shape[2] - w_length, w_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bbe43e-53eb-4faa-96d3-b1de7db14768",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_windows = []\n",
    "cv_split = cv.split(epochs_data_train)                                        # HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbc7bba-c410-4ea1-93cc-2f0b71f126a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each couple Training set / Validation set\n",
    "for train_idx, test_idx in cv_split:\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "    # fit CSP\n",
    "    # HERE\n",
    "    \n",
    "    # fit LDA\n",
    "    #HERE\n",
    "\n",
    "    # running classifier: test classifier on sliding window\n",
    "    score_this_window = []\n",
    "    # for each time window\n",
    "    for n in w_start:\n",
    "        # compute the CSP components on the time window\n",
    "        #HERE\n",
    "        \n",
    "        score_this_window.append(lda.score(X_test, y_test))\n",
    "    scores_windows.append(score_this_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298c2269-ad89-4301-aef9-259443f3f916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scores over time\n",
    "w_times = (w_start + w_length / 2.) / sfreq + epochs.tmin\n",
    "plt.plot(w_times, np.mean(scores_windows, 0), label='Score')\n",
    "plt.axvline(0, linestyle='--', color='k', label='Onset')\n",
    "plt.axhline(0.5, linestyle='-', color='k', label='Chance')\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('classification accuracy')\n",
    "plt.title('Classification score over time')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ece6e8d",
   "metadata": {},
   "source": [
    "### Cross-subject test\n",
    "We will try to apply this learnt model on another participant. \n",
    "#### ‚ùì **Question** ‚ùì: Load the data of the second participant.\n",
    "\n",
    "üî¥ HINTS üî¥  \n",
    "- `load_epoch`\n",
    "- `epochs.crop(tmin=.., tmax=..)`\n",
    "- `epochs.get_data()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439cf72f-b8c2-489f-b285-7e676a027dc0",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da6cf0e-8596-4530-b213-5d9d7d61cf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef964bc8-d02c-418f-a637-f7a192f28b80",
   "metadata": {},
   "source": [
    "#### ‚ùì **Question** ‚ùì: Evaluate the accuracy of the classifier $CSP+LDA$ trained on the first participant on the data of this second subject\n",
    "\n",
    "üî¥ HINTS üî¥  \n",
    "- To slice windows : `epochs_data_s02[:][:, :, n:(n + w_length)]`\n",
    "- `clf.score(X_test, y_test)` to compute directly accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47b7544",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([('CSP', csp), ('LDA', lda)])\n",
    "with HiddenPrints():\n",
    "    # Fit classifier\n",
    "    # HERE\n",
    "\n",
    "score_this_window = []\n",
    "# for each time window\n",
    "for n in w_start:\n",
    "    with HiddenPrints():\n",
    "        # Compute cross validation score on the time window\n",
    "        # HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d05938-f056-49a0-b911-5df1a701bea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_this_window)\n",
    "# Plot scores over time\n",
    "w_times = (w_start + w_length / 2.) / sfreq + epochs_s02.tmin\n",
    "print(len(w_times))\n",
    "print(len(score_this_window))\n",
    "plt.plot(w_times, score_this_window, label='Score')\n",
    "plt.axvline(0, linestyle='--', color='k', label='Onset')\n",
    "plt.axhline(0.5, linestyle='-', color='k', label='Chance')\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('classification accuracy')\n",
    "plt.title('Classification score over time')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd87a4c",
   "metadata": {},
   "source": [
    "# III - Improve the Brain Computer Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f711d1e",
   "metadata": {},
   "source": [
    "### Temporal filtering\n",
    "We used as a first approach a band-pass filtering between 7-35Hz. This can probably be improved. \n",
    "\n",
    "#### ‚ùì **Question** ‚ùì: Find another range (band) that leads to a higher mean accuracy ([cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4c350c-0aad-4e8c-b4dc-579f2ee7e84b",
   "metadata": {},
   "source": [
    "New data filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a905c8-8ac8-4cf1-8625-0a1779229870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef22632d-c2d7-49af-bd08-75ce33da69b4",
   "metadata": {},
   "source": [
    "Data classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307c5868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1152f624-357c-405f-b65e-e7d30fa69ca6",
   "metadata": {},
   "source": [
    "# IV - Evaluation with the [MOABB](http://moabb.neurotechx.com/docs/index.html) toolbox\n",
    "## Advanced temporal filtering: **filterbank**\n",
    "**Filterbank** idea is to divide and conquer: filter the data on different sub-bands, apply the same pipeline on each sub-band and finally gather the decisions.  \n",
    "In our previous approach, data were filtered only in one band, the one with the best performance.  \n",
    "\n",
    "The sub-bands design will follow roughly the well known band of humain activity:\n",
    "\n",
    "\n",
    "![Brain waves](img/brainwaves.png)  \n",
    "(source: https://www.fitmind.co/blog-collection/brainwaves-in-meditation-brain-wave-frequencies).\n",
    "\n",
    "We will take advantage again of the pipeline (CSP + LDA) as it seems to perform the best, and apply it with a Filter Bank approach. \n",
    "\n",
    "This time instead of converting data to Numpy format we will let [**MOABB**](https://github.com/NeuroTechX/moabb) handle everything and take advantage of the evaluation functions. Therefore, we will use [`FilterBankLeftRightImagery`](http://moabb.neurotechx.com/docs/generated/moabb.paradigms.FilterBankLeftRightImagery.html) paradigm from MOABB and the function [`WithinSessionEvaluation`](http://moabb.neurotechx.com/docs/generated/moabb.evaluations.WithinSessionEvaluation.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba4ac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from moabb.paradigms import FilterBankLeftRightImagery\n",
    "from moabb.pipelines.utils import FilterBank\n",
    "from moabb.evaluations import WithinSessionEvaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edc29d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Cho2017()\n",
    "ds.subject_list = [1,2] # Use only the two first subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aff0214",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines_fb = {}\n",
    "pipelines_fb[\"FBCSP+LDA\"] = make_pipeline(FilterBank(CSP(n_components=4)), LinearDiscriminantAnalysis())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4627e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = [[8, 12], [12, 16], [16, 20], [20, 24]]  # HERE\n",
    "paradigm = FilterBankLeftRightImagery(filters=filters)\n",
    "evaluation = WithinSessionEvaluation(\n",
    "    paradigm=paradigm, datasets=ds, overwrite=True)\n",
    "with HiddenPrints():\n",
    "    results_fb = evaluation.process(pipelines_fb)\n",
    "results_fb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24455120-a64c-462d-bb66-14dbaac62a78",
   "metadata": {},
   "source": [
    "Slight improvement of the performance ! Could be possible to do even better with filterbank taking advantage of higher frequencies !\n",
    "\n",
    "#### ‚ùì **Question** ‚ùì: Evaluate the previous approach with higher frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55959de4-dd6d-44d9-b66e-fb8e6e95e0fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cross-subjects\n",
    "One of the advantages of MOABB is that it allows to evaluate directly the previous pipeline ```pipelines_fb``` in the cross-subject context.\n",
    "\n",
    "#### ‚ùì **Question** ‚ùì: Use the MOABB evaluation [`CrossSubjectEvaluation`](http://moabb.neurotechx.com/docs/generated/moabb.evaluations.CrossSubjectEvaluation.html) to compute the scores in the cross-subject settings.\n",
    "\n",
    "üî¥ HINTS üî¥  \n",
    "- For `evaluation = CrossSubjectEvaluation` you need a `paradigm` and a `dataset`\n",
    "- Then you can run a pipeline `evaluation.process(pipeline)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71afc601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moabb.evaluations import CrossSubjectEvaluation\n",
    "# HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b09227c-e89c-4e1b-a61b-21cf7777c7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec6c126-8586-4aca-812b-b4da220c94f4",
   "metadata": {},
   "source": [
    "Performance are quite low... It is not suprising as cross-subject, along cross-session, classification is one of the most challenge of the BCI !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a74799",
   "metadata": {},
   "source": [
    "# V - Another approach: Riemannian geometry\n",
    "\n",
    "First, make sure you uploaded the pictures *riemann.png*, *riemann_embeding.png* and *brainwaves.png* in the folder of the notebook.\n",
    "\n",
    "For this Riemannian method, the first step is to compute covariance matrix for each epoch. The idea is to represent an epoch with the covariance matrix, instead of the raw data. It is depicted in the following picture (from P. L. C. Rodrigues, *Exploring invariances of multivariate time series via Riemannian geometry: validation on EEG data*).\n",
    "\n",
    "\n",
    "\n",
    "![Riemann embeding](img/riemann_embeding.png)  \n",
    "\n",
    "\n",
    "\n",
    "Then these covariance matrices are projected on the Tangent Space of the manifold of the SPD (Symetric Positive-Definite) matrices (the tangent space $\\approx$ the SPD manifold). \n",
    "\n",
    "\n",
    "\n",
    "![Riemann](img/riemann.png)\n",
    "\n",
    "\n",
    "\n",
    "The projection reduces the dimension of the matrix that becomes a vector. The vectors are then classified using a [Random Forest classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).\n",
    "\n",
    "$$ \\mbox{EEG data} \\rightarrow Covariance\\ matrix \\rightarrow Projection\\ on\\ Tangent\\ Space \\rightarrow Standard\\ Scaler \\rightarrow Random\\ Forest \\rightarrow\\mbox{prediction}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d55dc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyriemann.estimation import Covariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "epochs, labels = load_epoch(raws, event_id, 1, fmin = 5., fmax = 50)\n",
    "epoch_train = epochs.crop(tmin=1., tmax=2.)\n",
    "\n",
    "# Convert from MNE object to numpy Nd-array\n",
    "epochs_data_train = epochs.get_data()\n",
    "\n",
    "# Assemble feature extractor \n",
    "cov = Covariances(estimator='scm')\n",
    "ts = TangentSpace()\n",
    "ss = StandardScaler()\n",
    "\n",
    "# Assemble a classifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Use scikit-learn Pipeline\n",
    "clf = Pipeline([('cov', cov), ('ts', ts), ('ss', ss), ('rf', rf)])\n",
    "\n",
    "# Evaluate the resulting classifier using cross-validation\n",
    "scores = cross_val_score(clf, epochs_data_train, labels, cv=10, n_jobs=1,verbose=False)\n",
    "print('Mean score:', np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432bf5f8",
   "metadata": {},
   "source": [
    "Quite powerfull, even without any tunning ! It is probably possible to improve results with better pre-processing, testing other covariance matrix estimator. Here we used `\"scm\"` which stand for 'Sample Covariance Matrix', the maximum likelihood estimator. \n",
    "\n",
    "Some regularization could be considered: `\"lwf\"` for Ledowit Wolf, `\"oas\"` for Oracle Aproximating Shrinkage or \"`sch`\" (oui ma gat√©e) for Schaefer-Strimmer covariance. Some tunning of the RandomForestClassifier should also be considered. \n",
    "\n",
    "#### ‚ùì **Question** ‚ùì: Do better !!\n",
    "üî¥ HINTS üî¥  \n",
    "- [Regularized covariance estimation](https://pyriemann.readthedocs.io/en/latest/generated/pyriemann.utils.covariance.covariances.html#pyriemann.utils.covariance.covariances) \n",
    "- [Cross-validation](https://scikit-learn.org/stable/modules/cross_validation.html#computing-cross-validated-metrics) procedure for hyper-parameters selection of the [RandomForest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "- Try another classifier (for instance [XGBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7aef03",
   "metadata": {},
   "source": [
    "# VI - Built a better BCI using another pipeline on this Moter Imagery Dataset\n",
    "#### ‚ùì **Question** ‚ùì:  Improve one of the previous pipelines:\n",
    "- select parameters using cross-validation (e.g. n_components of CSP),\n",
    "- try other regularizations of the covariance matrices,\n",
    "- use other data preprocessing, filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c570b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf8bf3f8",
   "metadata": {},
   "source": [
    "#### ‚ùì **Question** ‚ùì: Try other classifiers, other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468204af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
